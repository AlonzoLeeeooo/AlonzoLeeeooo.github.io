<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chang Liu</title>

    <meta name="author" content="Chang Liu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chang Liu
                </p>
                <p>I am currently a PhD candidate in University of Science and Technology of China (USTC), supervised by <a href="https://faculty.ustc.edu.cn/dongeliu/en/index.htm">Prof. Dong Liu</a>.
                  I focus on applying foundation models to specific applications in an efficient, or even tuning-free manner.
                  You can find more information about me in the links below:
                </p>
                <p style="text-align:center">
                  <a href="lc980413@mail.ustc.edu.cn">E-mail</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=Y3NKd1wAAAAJ&hl=zh-CN&authuser=1">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.zhihu.com/people/liu-chang-82-34-78">Zhihu</a> &nbsp;/&nbsp;
                  <a href="https://github.com/AlonzoLeeeooo">Github</a>
                  <span class="highlight">(ðŸŒŸ Stars 1,400+)</span>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/JonBarron.jpg"><img style="width:50%;max-width:50%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="assets/homepage/chang-liu-photo.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I am particularly interested in a wide series of tasks, e.g., image inpainting, conditional image synthesis, video-to-video editing, and large language model fine-tuning, with some of my representative works listed as follows. Some of them are <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


      <h3 style="text-align: center;">Highlighted Research</h3>
      <tr onmouseout="stablev2v_stop()" onmouseover="stablev2v_start()" bgcolor="#ffffd0">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='stablev2v_image'>
              <img src='assets/bear-elephant-edited-video.gif' width=100%>
            </div>
            <img src='assets/bear-elephant-source-video.gif' width=100%>
          </div>
                  <script type="text/javascript">
                    function stablev2v_start() {
                      document.getElementById('stablev2v_image').style.opacity = "1";
                    }
  
                    function stablev2v_stop() {
                      document.getElementById('stablev2v_image').style.opacity = "0";
                    }
                    stablev2v_stop()
                  </script>
                </td>
      <td style="padding:8px;width:80%;vertical-align:middle">
        <span class="highlight">(ðŸŒŸ Stars 130)</span>
        <a href="https://github.com/AlonzoLeeeooo/StableV2V">
          <span class="papertitle">StableV2V: Stablizing Shape Consistency in Video-to-Video Editing</span>
        </a>
        <br>
        <strong>Chang Liu</strong>,
        <a href="https://qianduoduolr.github.io/">Rui Li</a>,
        Kaidong Zhang,
        Yunwei Lan, 
        <a href="https://faculty.ustc.edu.cn/dongeliu/en/index.htm">Dong Liu</a>*
        <br>
        <em>arXiv</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2411.11045">[Paper]</a>
        /
        <a href="https://github.com/AlonzoLeeeooo/StableV2V">[GitHub]</a>
        /
        <a href="https://alonzoleeeooo.github.io/StableV2V/">[Project]</a>
        <p></p>
        <p>
        This work focuses on the <u>shape misalignment</u> problem in video-to-video editing, where we propose a <u>training-free</u> paradigm to ensure the consistency between object motions and user prompts. Also, we collect an evaluation benchmark named <a href="https://huggingface.co/datasets/AlonzoLeeeooo/DAVIS-Edit"><u>DAVIS-Edit</u></a> for the community.
        </p>
      </td>
    </tr>



    <tr onmouseout="lacon_stop()" onmouseover="lacon_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='lacon_image'>
            <img src='assets/homepage/lacon-result.png' width=100%>
          </div>
          <img src='assets/homepage/lacon-sketch.png' width=100%>
        </div>
                <script type="text/javascript">
                  function lacon_start() {
                    document.getElementById('lacon_image').style.opacity = "1";
                  }

                  function lacon_stop() {
                    document.getElementById('lacon_image').style.opacity = "0";
                  }
                  lacon_stop()
                </script>
              </td>
    <td style="padding:8px;width:80%;vertical-align:middle">
      <span class="highlight">(ðŸŒŸ Stars 32)</span>
      <a href="https://github.com/AlonzoLeeeooo/LCDG">
        <span class="papertitle">LaCon: Late-Constraint Diffusion for Steerable Guided Image Synthesis</span>
      </a>
      <br>
      <strong>Chang Liu</strong>,
      <a href="https://qianduoduolr.github.io/">Rui Li</a>,
      Kaidong Zhang,
      Xin Luo, 
      <a href="https://faculty.ustc.edu.cn/dongeliu/en/index.htm">Dong Liu</a>*
      <br>
      <em>arXiv</em>, 2023
      <br>
      <a href="https://arxiv.org/abs/2305.11520">[Paper]</a>
      /
      <a href="https://github.com/AlonzoLeeeooo/LCDG">[GitHub]</a>
      /
      <a href="https://alonzoleeeooo.github.io/LCDG">[Project]</a>
      <p></p>
      <p>
      This work is motivated by the <u>limited generalization ability</u> in prevailing conditional image synthesis studies, where it perform the task by aligning the internal features of diffusion models with external control signals, and trains an efficient condition adapter for generalizable use. Promising performance, robust generalization ability, and superior efficiency are observed.
      </p>
    </td>
  </tr>


  <tr onmouseout="sketchrefiner_stop()" onmouseover="sketchrefiner_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='sketchrefiner_image'>
          <img src='assets/homepage/sketchrefiner-result.png' width=100%>
        </div>
        <img src='assets/homepage/sketchrefiner-input.png' width=100%>
      </div>
              <script type="text/javascript">
                function sketchrefiner_start() {
                  document.getElementById('sketchrefiner_image').style.opacity = "1";
                }

                function sketchrefiner_stop() {
                  document.getElementById('sketchrefiner_image').style.opacity = "0";
                }
                sketchrefiner_stop()
              </script>
            </td>
  <td style="padding:8px;width:80%;vertical-align:middle">
    <span class="highlight">(ðŸŒŸ Stars 36)</span>
    <a href="https://github.com/AlonzoLeeeooo/SketchRefiner">
      <span class="papertitle">Towards Interactive Image Inpainting via Robust Sketch Refinement</span>
    </a>
    <br>
    <strong>Chang Liu</strong>,
    <a href="https://scholar.google.com/citations?user=rMaBuHUAAAAJ&hl=zh-CN&oi=ao">Shunxin Xu</a>,
    <a href="https://scholar.google.com/citations?hl=zh-CN&user=gHEd-IMAAAAJ">Jialun Peng</a>,
    Kaidong Zhang, 
    <a href="https://faculty.ustc.edu.cn/dongeliu/en/index.htm">Dong Liu</a>*
    <br>
    <em>TMM</em>, 2024
    <br>
    <a href="https://ieeexplore.ieee.org/abstract/document/10533842">[Paper]</a>
    /
    <a href="https://github.com/AlonzoLeeeooo/SketchRefiner">[GitHub]</a>
    /
    <a href="https://alonzoleeeooo.github.io/SketchRefiner/">[Project]</a>
    <p></p>
    <p>
    This work aims to improve the use of <u>real-world user sketches</u> in the task of interactive image inpainting.
    Specifically, it utilizes a sketch refinement network to firstly calibrate the input sketches, and then projects it onto the feature space to obtain multi-scale alignment with the inpainting networks, eventually handling real user sketches more effectively.
    </p>
  </td>
</tr>

<tr onmouseout="rrg_stop()" onmouseover="rrg_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one" style="display: flex; align-items: center; height: 80%;">
      <div class="two" id='rrg_image'>
      </div>
      <img src='assets/homepage/r2-llm.png' width=100% style="display: block; margin: auto;">
    </div>
            <script type="text/javascript">
              function rrg_start() {
                document.getElementById('rrg_image').style.opacity = "1";
              }

              function rrg_stop() {
                document.getElementById('rrg_image').style.opacity = "0";
              }
              rrg_stop()
            </script>
          </td>
<td style="padding:8px;width:80%;vertical-align:middle">
  <span class="highlight">(ðŸŒŸ Stars 47)</span>
    <span class="papertitle">Bootstrapping Large Language Models for Radiology Report Generation</span>
  <br>
  <strong>Chang Liu</strong>,
  Yuanhe Tian,
  Weidong Chen,
  Yan Song*,
  Yongdong Zhang,
  <br>
  <em>AAAI</em>, 2024
  <br>
  <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29826">[Paper]</a>
  /
  <a href="https://github.com/synlp/R2-LLM">[GitHub]</a>
  <p></p>
  <p>
  This work aims to adapt large language models for the domain-specific application, i.e., radiology report generation, along with an In-domain Instance Induction (I3) and a Coarse-to-Fine Decoding (C2FD) strategies to efficiently fine-tune the LLM.
  </p>
</td>
</tr>

<tr onmouseout="rrg_stop()" onmouseover="rrg_start()"></tr>
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one" style="display: flex; align-items: center; height: 80%;">
      <div class="two" id='rrg_image'>
      </div>
      <img src='assets/homepage/rrg-survey.png' width=100% style="display: block; margin: auto;">
    </div>
            <script type="text/javascript">
              function rrg_start() {
                document.getElementById('rrg_image').style.opacity = "1";
              }

              function rrg_stop() {
                document.getElementById('rrg_image').style.opacity = "0";
              }
              rrg_stop()
            </script>
          </td>
<td style="padding:8px;width:80%;vertical-align:middle">
  <span class="highlight">(ðŸŒŸ Stars 84)</span>
  <span class="papertitle">A Systematic Review of Deep Learning-based Rearch for Radiology Report Generation</span>
  <br>
  <strong>Chang Liu</strong>,
  Yuanhe Tian,
  Yan Song*,
  <br>
  <em>arXiv</em>, 2023
  <br>
  <a href="https://arxiv.org/abs/2311.14199">[Paper]</a>
  /
  <a href="https://github.com/synlp/RRG-Review">[GitHub]</a>
  <p></p>
  <p>
    This work offers a comprehensive review of deep learning-based research for radiology report generation, from perspectives of preresquisites, methology, datasets, evaluation metrics, and performance analysis. An <u>open-sourced GitHub repository</u> is maintained in order to summarize all related studies and resources in this task for the community.
  </p>
</td>
</tr>
          
        </td>
      </tr>
    </table>
  </body>

  <h3 style="text-align: center;">Others</h3>
Here are other works that I participated:
<div class="content has-text-justified">
  <p>
    <ul>
      <li><span class="highlight">[AAAI 2025]</span> <a><b>Exploiting Diffusion Prior for Real-World Image Dehazing with Unpaired Training.</b></a> <em>Yunwei Lan, Zhigao Cui, <strong>Chang Liu</strong>, Jialun Peng, Nian Wang, Xin Luo, Dong Liu*.</em> 
      </li>
     <li><span class="highlight">[NAACL 2024]</span> <a href="https://aclanthology.org/2024.findings-naacl.194/"><b>Aspect-based Sentiment Analysis with Context Denoising.</b></a> <em>Yuanhe Tian, <strong>Chang Liu</strong>, Yan Song*, Fei Xia, Yongdong Zhang.</em> 
     </li>
      <li><span class="highlight">[arXiv 2024]</span> <a href="https://arxiv.org/abs/2411.15551"><b>NeRF Inpainting with Geometric Diffusion Prior and Balanced Score Distillation.</b></a> <em>Menglin Zhang, Xin Luo, Yunwei Lan, <strong>Chang Liu</strong>, Rui Li, Kaidong Zhang, Ganlin Yang, Dong Liu*.</em> 
      </li>
      <li><span class="highlight">[arXiv 2024]</span> <a href="https://arxiv.org/abs/2312.04326"><b>IDesigner: A High-Resolution and Complex-Prompt Following Text-to-Image Diffusion Model for Interior Design.</b></a> <em>Ruyi Gan, Xiaojun Wu, Junyu Lu, Yuanhe Tian, Dixiang Zhang, Ziwei Wu, Renliang Sun, <strong>Chang Liu</strong>, Jiaxing Zhang*, Pingjian Zhang, Yan Song.</em> 
      </li></ul>
  </p>
</div>
Here are some open-sourced projects that I lead:
<div class="content has-text-justified"></div>
    <ul>
     <li><span class="highlight">(ðŸŒŸ Stars 505)</span> <a href="https://github.com/AlonzoLeeeooo/awesome-text-to-image-studies"><b>awesome-text-to-image-studies</b></a>: A collectio of awesome text-to-image studies. 
     </li>
      <li><span class="highlight">(ðŸŒŸ Stars 442)</span> <a href="https://github.com/AlonzoLeeeooo/awesome-video-generation"><b>awesome-video-generation</b></a>: A collection of awesome video generation studies.
      </li>
      <li><span class="highlight">(ðŸŒŸ Stars 224)</span> <a href="https://github.com/AlonzoLeeeooo/awesome-image-inpainting-studies"><b>awesome-image-inpainting-studies</b></a>: A collection of awesome image inpainting sutdies.
      </li>
      <li><span class="highlight">(ðŸŒŸ Stars 18)</span> <a href="https://github.com/AlonzoLeeeooo/awesome-radiology-report-generation"><b>awesome-radiology-report-generation</b></a>: A collection of awesome radiology report generation sutdies.
      </li>
      <li><span class="highlight">(ðŸŒŸ Stars 6)</span> <a href="https://github.com/AlonzoLeeeooo/shape-guided-controlnet"><b>shape-guided-controlnet</b></a>: A re-implementation of ControlNet trained with shape masks.
      </li>
      <li><span class="highlight">(ðŸŒŸ Stars 4)</span> <a href="https://github.com/AlonzoLeeeooo/ControlNeXt-svd-shape"><b>ControlNeXt-svd-shape</b></a>: A re-implementation of ControlNeXt trained with shape guidance.
      </li></ul>
  </p>
</div>

</html>